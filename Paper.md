
# Content
1. [[Remote Sensing](#Remote_Sensing)]
2. [[segmentation and detection](#Segmentation_and_Detection)]
3. [[Open vocabulary](#open_vocabulary)]


<a name="Remote_Sensing"></a> 
## Remote Sensing
1. [2025 arXiv] **DynamicEarth: How Far are We from Open-Vocabulary Change Detection?** [[paper]](https://arXiv.org/abs/2501.12931) [[code]](https://github.com/likyoo/DynamicEarth)
2. [2025 TGRS] **A Unified Framework With Multimodal Fine-Tuning for Remote Sensing Semantic Segmentation.** [[paper]](https://ieeexplore.ieee.org/document/11063320) [[code]](https://github.com/sstary/SSRS)
3. [2025 ICASSP] **Enhancing Remote Sensing Vision-Language Models for Zero-Shot Scene Classification.** [[paper]](https://arXiv.org/abs/2409.00698) [[code]](https://github.com/elkhouryk/RS-TransCLIP)
5. [2025 ICCV] **Dynamic Dictionary Learning for Remote Sensing Image Segmentation.** [[paper]](https://arXiv.org/pdf/2503.06683) [[code]](https://github.com/XavierJiezou/D2LS)
6. [2025 ICCV] **GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks.** [[paper]](https://arxiv.org/pdf/2411.19325) [[code]](https://github.com/The-AI-Alliance/GEO-Bench-VLM)
7. [2025 ICCV] **SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation.** [[paper]](https://arXiv.org/abs/2507.12857) [[code]](https://github.com/HuangShiqi128/SCORE)
8. [2025 ICCV] **When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning.** [[paper]](https://arXiv.org/pdf/2503.07588) [[code]](https://github.com/VisionXLab/LRS-VQA)
9. [2025 AAAI] **ZoRI: Towards discriminative zero-shot remote sensing instance segmentation.** [[paper]](https://arXiv.org/abs/2412.12798) [[code]](https://github.com/HuangShiqi128/ZoRI)
10. [2024 NIPS] **Segment Any Change.** [[paper]](https://proceedings.NIPS.cc/paper_files/paper/2024/file/9415416201aa201902d1743c7e65787b-Paper-Conference.pdf) [[code]](https://github.com/Z-Zheng/pytorch-change-models)
11. [2025 CVPR] **SegEarth-OV: Towards Training-Free Open-Vocabulary Segmentation for Remote Sensing Images.** [[paper]](https://arXiv.org/abs/2410.01768) [[code]](https://github.com/likyoo/SegEarth-OV)
12. [2025 CVPR] **XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?** [[paper]](https://arXiv.org/abs/2503.23771) [[code]](https://github.com/EvolvingLMMs-Lab/XLRS-Bench)
13. [2025 CVPR] **Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation.** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exact_Exploring_Space-Time_Perceptive_Clues_for_Weakly_Supervised_Satellite_Image_CVPR_2025_paper.pdf) [[code]](https://github.com/MiSsU-HH/Exact)
14. [2025 Arxiv] **SegEarth-OV-2: Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images** [[paper]](https://arxiv.org/abs/2508.18067)  [[code]](https://github.com/earth-insights/SegEarth-OV-2)
15. [2025 AAAI] **Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation** [[paper]](https://arxiv.org/abs/2412.19492) [[code]](https://github.com/yecy749/GSNet)
16. [2025 Arxiv] **InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition** [[paper]](https://arxiv.org/pdf/2505.15818) [[code]](https://github.com/VoyagerXvoyagerx/InstructSAM)
17. [2025 Arxiv] **DescribeEarth: Describe Anything for Remote Sensing Images** [[paper]](https://arxiv.org/pdf/2509.25654v1) [[code]](https://github.com/earth-insights/DescribeEarth)
18. [2025 NIPS] **GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset** [[paper]](https://arxiv.org/abs/2507.14697) [[code]](https://github.com/Z-ZW-WXQ/GTPBD)
19. [2025 Arxiv] **RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing** [[paper]](https://arxiv.org/abs/2509.18897) [[code]](https://rs3dbench.github.io)
20. [2025 Arxiv] **DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation** [[paper]](https://arxiv.org/pdf/2509.00598) [[code]](https://github.com/designer1024/DGL-RSIS)
21. [2025 TGRS] **A Unified SAM-Guided Self-Prompt Learning Framework for Infrared Small Target Detection** [[paper]](https://ieeexplore.ieee.org/document/11172325) [[code]](https://github.com/fuyimin96/SAM-SPL)
22. [2025 TGRS] **Semantic Prototyping With CLIP for Few-Shot Object Detection in Remote Sensing Images** [[paper]](https://ieeexplore.ieee.org/document/10930588)
23. [2025 Arxiv ] **Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing** [[paper]](https://arxiv.org/pdf/2509.12040)[[code]](https://github.com/LiBingyu01/RSKT-Seg?tab=readme-ov-file)


<a name="Segmentation_and_Detection"></a>
## Segmentation and Detection
1. [2015 CVPR] **FCN: Fully Convolutional Networks for Semantic Segmentation.** [[paper]](https://arXiv.org/abs/1411.4038) [[code]](https://github.com/BVLC/caffe/wiki/Model-Zoo#fcn)
2. [2016 MICCAI] **UNet: Convolutional Networks for Biomedical Image Segmentation.** [[paper]](https://arXiv.org/pdf/1505.04597)
3. [2017 arXiv] **DeepLabV3: Rethinking atrous convolution for semantic image segmentation.** [[paper]](https://arXiv.org/pdf/1706.05587)
4. [2018 CVPR] **DeepLabV3+: Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation.** [[paper]](https://arXiv.org/pdf/1802.02611)
5. [2019 CVPR] **Semantic FPN: Panoptic Feature Pyramid Networks.** [[paper]](https://arXiv.org/pdf/1901.02446)
6. [2021 CVPR] **SETR: Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers.** [[paper]](https://arXiv.org/pdf/2012.15840) [[code]](https://github.com/fudan-zvg/SETR)
7. [2021 ICCV] **Segmenter: Transformer for Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2105.05633) [[code]](https://github.com/rstrudel/segmenter)
8. [2021 NIPS] **SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers.** [[paper]](https://arXiv.org/pdf/2105.15203) [[code]](https://github.com/NVlabs/SegFormer)
9. [2021 CVPR] **MaskFormer: Per-Pixel Classification is Not All You Need for Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2107.06278) [[code]](https://github.com/facebookresearch/MaskFormer)
10. [2022 CVPR] **Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation.** [[paper]](https://arXiv.org/pdf/2112.01527) [[code]](https://github.com/facebookresearch/Mask2Former)
11. [2024 CVPR] **Rein: Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2312.04265) [[code]](https://github.com/w1oves/Rein)
12. [2015 NIPS] **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.** [[paper]](https://arXiv.org/pdf/1506.01497)
13. [2020 ECCV] **DETR: End-to-End Object Detection with Transformers.** [[paper]](https://arXiv.org/pdf/2005.12872) [[code]](https://github.com/facebookresearch/detr)
14. [2021 ICLR] **Deformable DETR: Deformable Transformers for End-to-End Object Detection.** [[paper]](https://arXiv.org/pdf/2010.04159) [[code]](https://github.com/fundamentalvision/Deformable-DETR)
15. [2023 ICLR] **DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection.** [[paper]](https://arXiv.org/pdf/2203.03605) [[code]](https://github.com/IDEA-Research/DINO)


<a name="open_vocabulary"></a>
## Open vocabulary
### segmentation
1. [2022 CVPR] **ZegFormer: Decoupling Zero-Shot Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2112.07910) [[code]](https://github.com/dingjiansw101/ZegFormer)
3. [2022 ECCV] **ViL-Seg: Open-World Semantic Segmentation via Contrasting and Clustering Vision-Language Embeddings.** [[paper]](https://arXiv.org/pdf/2207.08455v2)
5. [2022 CVPR] **GroupViT: Semantic Segmentation Emerges from Text Supervision (Open-Vocabulary Zero-Shot).** [[paper]](https://arXiv.org/pdf/2202.11094) [[code]](https://github.com/NVlabs/GroupViT)
6. [2022 ECCV] **OpenSeg: Scaling Open-Vocabulary Image Segmentation with Image-Level Labels.** [[paper]](https://arXiv.org/pdf/2112.12143)
7. [2023 CVPR] **FreeSeg: Unified, Universal, and Open-Vocabulary Image Segmentation.** [[paper]](https://arXiv.org/pdf/2303.17225) [[code]](https://github.com/bytedance/FreeSeg)
8. [2023 ICML] **SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation (Zero-Shot).** [[paper]](https://arXiv.org/pdf/2211.14813) [[code]](https://github.com/ArrowLuo/SegCLIP)
9. [2023 CVPR] **ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2212.03588) [[code]](https://github.com/ZiqinZhou66/ZegCLIP)
10. [2023 CVPR] **X-Decoder: Generalized Decoding for Pixel, Image, and Language.** [[paper]](https://arXiv.org/pdf/2212.11270) [[code]](https://github.com/microsoft/X-Decoder/tree/main)
11. [2023 CVPR] **ODISE: Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models.** [[paper]](https://arXiv.org/pdf/2303.04803) [[code]](https://github.com/NVlabs/ODISE)
12. [2023 ICML] **MaskCLIP: Open-Vocabulary Universal Image Segmentation with MaskCLIP.** [[paper]](https://arXiv.org/pdf/2208.08984) [[code]](https://github.com/mlpc-ucsd/MaskCLIP)
13. [2023 CVPR] **SAN: Side Adapter Network for Open-Vocabulary Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2302.12242) [[code]](https://github.com/MendelXu/SAN)
14. [2024 ECCV] **CLIP-DINOiser: Teaching CLIP a few DINO tricks for open-vocabulary semantic segmentation.** [[paper]](https://arXiv.org/pdf/2312.12359) [[code]](https://github.com/wysoczanska/clip_dinoiser)
15. [2024 CVPR] **SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation.** [[paper]](https://arXiv.org/pdf/2311.15537) [[code]](https://github.com/xb534/SED)
16. [2024 TPAMI] **Review: Towards Open Vocabulary Learning: A Survey.** [[paper]](https://arXiv.org/pdf/2306.15880) [[code]](https://github.com/jianzongwu/Awesome-Open-Vocabulary)
17. [2025 ICCV] **Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction.** [[paper]](https://arXiv.org/abs/2412.06244) [[code]](https://github.com/HVision-NKU/DenseVLM)
18. [2024 CVPR] **Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation.** [[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Exploring_Regional_Clues_in_CLIP_for_Zero-Shot_Semantic_Segmentation_CVPR_2024_paper.pdf) [[code]](https://github.com/Jittor/JSeg)
19. [2025 CVPR] **DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception.** [[paper]](https://arXiv.org/pdf/2505.04410) [[code]](https://github.com/xiaomoguhz/DeCLIP)
20. [2025 arXiv] **REFAM: Attention magnets for zero-shot referral segmentaion** [[paper]](https://arxiv.org/pdf/2509.22650v1)


### object detection
1. [2021 CVPR] **Open-Vocabulary Object Detection Using Captions.** [[paper]](https://arXiv.org/pdf/2011.10678) [[code]](https://github.com/alirezazareian/ovr-cnn)
2. [2022 ICLR] **ViLD: Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation.** [[paper]](https://arXiv.org/pdf/2104.13921) [[code]](https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild)
3. [2022 CVPR] **GLIP: Grounded Language-Image Pre-training.** [[paper]](https://arXiv.org/pdf/2112.03857) [[code]](https://github.com/microsoft/GLIP)
4. [2022 NIPS] **GLIPv2: Unifying Localization and Vision-Language Understanding.** [[paper]](https://arXiv.org/pdf/2206.05836) [[code]](https://github.com/microsoft/GLIP)
5. [2024 ICCV] **Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection** [[paper]](https://arxiv.org/pdf/2303.05499) [[code]](https://github.com/IDEA-Research/GroundingDINO)


<a name="Active"></a>
### Active learning/ Data Selection
1. [2025 arXiv] **Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories** [[paper]](https://arxiv.org/pdf/2510.01454v1) [[code]](https://bigml-cs-ucla.github.io/XMAS-project-page/)
2. [2025 arXiv] **AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding** [[paper]](https://arxiv.org/pdf/2510.02778v1) [[code]](https://github.com/Xian867/AdaRD-Key)
3. [2025 arXiv] **Diffusion Synthesis: Data Factory with Minimal Human Effort Using VLMs** [[paper]](https://arxiv.org/pdf/2510.05722v1)


<a name="Time_series"></a>
### Time series
1. [2025 ICLR] **FreDF: Learning to Forecast in the Frequency Domain** [[paper]](https://arxiv.org/pdf/2402.02399) [[code]](https://github.com/Master-PLC/FreDF)
2. [2025 ICML] **Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting** [[paper]](https://arxiv.org/pdf/2502.04395) [[code]](https://github.com/CityMind-Lab/ICML25-TimeVLM)
3. [2024 AAAI] **MSGNet: Learning Multi-Scale Inter-Series Correlations for Multivariate Time Series Forecasting** [[paper]](https://arxiv.org/pdf/2401.00423) [[code]](https://github.com/YoZhibo/MSGNet)















