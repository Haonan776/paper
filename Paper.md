# Content
1. [Remote Sensing]([https://github.com/Haonan776/paper/blob/main/Paper.md#remote-sensing])
2. [Training Free Segmentation]
3. [Zero shot Classification]
4. [Visual Place Recognition]
5. [Weakly Supervised Semantic Segmentation]
6. [Open vocabulary]
7. [segmentation and detection]
8. [Other]


# Remote Sensing
1. [2025 arXiv]DynamicEarth: How Far are We from Open-Vocabulary Change Detection?[paper] [code]
2. [2025 TGRS] A Unified Framework With Multimodal Fine-Tuning for Remote Sensing Semantic Segmentation. [paper] [code]
3. [2025 ICASSP] Enhancing Remote Sensing Vision-Language Models for Zero-Shot Scene Classification. [paper] [code]
4. [2025 ICCV] Dynamic Dictionary Learning for Remote Sensing Image Segmentation. [paper] [code]
5. [2024 NIPS] Segment Any Change. [paper] [code]
6. [2025 CVPR] SegEarth-OV: Towards Training-Free Open-Vocabulary Segmentation for Remote Sensing Images. [paper] [code]
7. [2025 CVPR] XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery? [paper] [code]
8. [2025 CVPR] Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation. [paper] [code]
9. [2025 Arxiv] SegEarth-OV-2: Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images [paper] [code]
10. [2025 AAAI] Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation [paper] [code]
11. [2025 Arxiv] InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition [paper] [code]
12. [2025 Arxiv] DescribeEarth: Describe Anything for Remote Sensing Images [paper] [code]
13. [2025 NIPS] GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset [paper] [code]
14. [2025 Arxiv] RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing [paper] [code]
15. [2025 Arxiv] DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation [paper] [code]
16. [2025 TGRS] A Unified SAM-Guided Self-Prompt Learning Framework for Infrared Small Target Detection [paper] [code]
17. [2025 TGRS] Semantic Prototyping With CLIP for Few-Shot Object Detection in Remote Sensing Images [paper]


# Training Free Segmentation
1. [2024 CVPR] Clip-diy: Clip dense inference yields open-vocabulary semantic segmentation for-free [paper][code]
2. [2024 CVPR] Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation [paper] [code]
3. [2024 ECCV] Diffusion Models for Open-Vocabulary Segmentation [paper] [code]
4. [2024 ECCV] ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference [paper] [code]
5. [2024 ECCV] SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference [paper] [code]
6. [2024 ECCV] Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation [paper] [code]
7. [2024 ECCV] Proxyclip: Proxy attention improves clip for open-vocabulary segmentation [paper] [code]


# Zero shot Classification
1. [2024 CVPR] On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning? [paper] [code]
2. [2024 CVPR] Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation [paper] [code]
3. [2024 CVPR] Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion [paper] [code]
4. [2024 ECCV] OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation [paper] [code]
5. [2024 ICCV] Zero-guidance Segmentation Using Zero Segment Labels [paper] [code]
6. [2024 NIPS] DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut [paper] [code]
7. [2025 ICLR] Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model [paper] [code]


# Visual Place Recognition
1. [2022 CVPR] CosPlace: Rethinking Visual Geo-localization for Large-Scale Applications. [paper] [code]
2. [2024 CVPR] CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition. [paper] [code]
3. [2024 CVPR] BoQ: A Place is Worth a Bag of Learnable Queries. [paper] [code]
4. [2024 NIPS] SuperVLAD: Compact and Robust Image Descriptors for Visual Place Recognition. [paper] [code]
5. [2024 ECCV] Revisit Anything: Visual Place Recognition via Image Segment Retrieval. [paper] [code]
6. [2025 arXiv] HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition. [paper] [code]
7. [2023 IROS] Training-Free Attentive-Patch Selection for Visual Place Recognition. [paper]


# Weakly Supervised Semantic Segmentation
1. [2025 AAAI] MoRe: Class Patch Attention Needs Regularization for Weakly Supervised Semantic Segmentation. [paper] [code]
2. [2025 CVPR] PROMPT-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis. [paper] [code]
3. [2025 CVPR] Exploring CLIPâ€™s Dense Knowledge for Weakly Supervised Semantic Segmentation. [paper] [code]
4. [2025 CVPR] GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery. [paper] [code]
5. [2025 arXiv] TeD-Loc: Text Distillation for Weakly Supervised Object Localization. [paper] [code]
6. [2025 arXiv] Image Augmentation Agent for Weakly Supervised Semantic Segmentation. [paper]
7. [2025 CVPR] Multi-Label Prototype Visual Spatial Search for Weakly Supervised Semantic Segmentation. [paper]
8. [2025 CVPRW] Prompt Categories Cluster for Weakly Supervised Semantic Segmentation. [paper]
9. [2025 arXiv] No time to train! Training-Free Reference-Based Instance Segmentation. [paper] [code]


# Open vocabulary
1. [2022 ECCV] ViL-Seg: Open-World Semantic Segmentation via Contrasting and Clustering Vision-Language Embeddings. [paper]
2. [2022 CVPR] GroupViT: Semantic Segmentation Emerges from Text Supervision (Open-Vocabulary Zero-Shot). [paper] [code]
3. [2022 ECCV] OpenSeg: Scaling Open-Vocabulary Image Segmentation with Image-Level Labels. [paper]
4. [2023 CVPR] FreeSeg: Unified, Universal, and Open-Vocabulary Image Segmentation. [paper] [code]
5. [2023 ICML] SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation (Zero-Shot). [paper] [code]
6. [2023 CVPR] ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation. [paper] [code]
7. [2023 CVPR] X-Decoder: Generalized Decoding for Pixel, Image, and Language. [paper] [code]
8. [2023 CVPR] ODISE: Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models. [paper] [code]
9. [2023 ICML] MaskCLIP: Open-Vocabulary Universal Image Segmentation with MaskCLIP. [paper] [code]
10.[2023 CVPR] SAN: Side Adapter Network for Open-Vocabulary Semantic Segmentation. [paper] [code]
11.[2024 ECCV] CLIP-DINOiser: Teaching CLIP a few DINO tricks for open-vocabulary semantic segmentation. [paper] [code]
12.[2024 CVPR] SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation. [paper] [code]
13.[2024 TPAMI] Review: Towards Open Vocabulary Learning: A Survey. [paper] [code]
14.[2025 ICCV] Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction. [paper] [code]
15.[2024 CVPR] Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation. [paper] [code]
16.[2025 CVPR] DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception. [paper] [code]
17. [2025 arXiv] REFAM: Attention magnets for zero-shot referral segmentaion [paper]
   
   
















